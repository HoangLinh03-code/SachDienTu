# import vertexai
# import os
# from vertexai.generative_models import GenerativeModel, Part, GenerationConfig
# from google import genai
# from google.genai import types

# class VertexClient:
#     def __init__(self, project_id, creds, model, region="global"):
#         self.model

#     def send_data_to_AI(self, prompt, file_paths=None, temperature=0.5, top_p=0.8):
#         parts = []

#         # N·∫øu c√≥ nhi·ªÅu file PDF
#         if file_paths:
#             for file_path in file_paths:
#                 with open(file_path, "rb") as f:
#                     pdf_bytes = f.read()
#                 parts.append(
#                     Part.from_data(data=pdf_bytes, mime_type="application/pdf")
#                 )

#         # Th√™m prompt d·∫°ng text
#         parts.append(Part.from_text(prompt))

#         # Config sinh n·ªôi dung
#         generation_config = GenerationConfig(
#             temperature=temperature,
#             top_p=top_p
#         )

#         response = self.model.generate_content(
#             parts, generation_config=generation_config
#         )
#         return response.text


import os
import base64
from google import genai
from google.genai import types

class VertexClient:
    def __init__(self, project_id, creds, model_name="gemini-2.5-pro", location="us-central1"):
        # 1. Gi·ªØ nguy√™n c·∫•u h√¨nh ƒë√£ test th√†nh c√¥ng ·ªü test_connect
        self.model_name = model_name
        self.location = location
        
        print(f"‚ö° [VertexClient] K·∫øt n·ªëi: {model_name} | Region: {location}")
        
        self.client = genai.Client(
            vertexai=True,
            project=project_id,
            location=location,
            credentials=creds
        )

    def send_data_to_AI(self, prompt, file_paths=None, temperature=0.5, top_p=0.8):
        contents = []

        # 2. X·ª≠ l√Ω PDF: C√°ch ƒë√≥ng g√≥i an to√†n nh·∫•t cho SDK m·ªõi
        if file_paths:
            for file_path in file_paths:
                if os.path.exists(file_path):
                    with open(file_path, "rb") as f:
                        file_bytes = f.read()
                    
                    # D√πng types.Part.from_bytes l√† chu·∫©n nh·∫•t
                    # Nh∆∞ng ƒë·ªÉ ch·∫Øc ch·∫Øn, ta ki·ªÉm tra xem file c√≥ r·ªóng kh√¥ng
                    if len(file_bytes) == 0:
                        print(f"‚ö†Ô∏è File r·ªóng: {file_path}")
                        continue
                        
                    pdf_part = types.Part.from_bytes(
                        data=file_bytes,
                        mime_type="application/pdf"
                    )
                    contents.append(pdf_part)

        # 3. Th√™m Prompt Text
        contents.append(types.Part.from_text(text=prompt))

        # 4. Config
        config = types.GenerateContentConfig(
            temperature=temperature,
            top_p=top_p
        )

        try:
            print(f"‚è≥ ƒêang g·ª≠i {len(contents)} parts t·ªõi {self.model_name}...")
            
            # G·ª≠i request
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=[types.Content(role="user", parts=contents)],
                config=config
            )
            
            return response.text

        except Exception as e:
            err_msg = str(e)
            print(f"‚ùå L·ªói API: {err_msg}")
            
            # Ph√¢n t√≠ch l·ªói c·ª• th·ªÉ gi√∫p b·∫°n
            if "400" in err_msg:
                if "loading the file" in err_msg or "mime" in err_msg:
                    print("üëâ G·ª£i √Ω: Model n√†y c√≥ th·ªÉ ƒëang k√©n file PDF. Th·ª≠ convert sang ·∫£nh ho·∫∑c text.")
                elif "not supported" in err_msg:
                    print("üëâ G·ª£i √Ω: Model 'Preview' n√†y c√≥ th·ªÉ ch∆∞a h·ªó tr·ª£ Multimodal (ch·ªâ nh·∫≠n Text).")
            return None